{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d58e2f2",
   "metadata": {},
   "source": [
    "# Exploring the FuseTS Toolbox: Fusing Optical and SAR Data for Phenology Analysis\n",
    "\n",
    "Welcome to the showcase of the FuseTS library, an integral part of the AI4FOOD project, presented at the FOSS4G conference. In this Jupyter notebook, we will demonstrate how the FuseTS library enables users to effectively fuse optical and SAR data, harnessing the power of fused data sets combined time series analytics for extracting valuable phenology information.\n",
    "\n",
    "Throughout this notebook, we will compare the results obtained from a raw dataset with those obtained from the fused dataset, illustrating the significant improvements in extracting phenology information. By integrating optical data, which provides detailed spectral information, with SAR data, which excels in all-weather and day-night imaging, the FuseTS library empowers users to unlock deeper insights into vegetation dynamics and crop monitoring.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- You can start from a clean **Python 3.8** environment. During this notebook, we'll be installing the necessary dependencies.\n",
    "- In this notebook, we utilize openEO to retrieve time series data. To leverage the full range of openEO features, you can create a free trial account on the [openEO Platform](https://docs.openeo.cloud/join/free_trial.html) and receive 1000 free credits, enabling you to execute the functionalities showcased in this notebook.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b7f006d",
   "metadata": {},
   "source": [
    "Lets start with importing the different libraries that we need within this notebook.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f517e4f-229f-4d85-9f1e-9f43d614a6cb",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "First of all we need to make sure that all our dependencies are correctly installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not execute this cell when using the Docker image\n",
    "# !pip install numpy==1.23.5 cython\n",
    "# !pip install ../../.\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b24fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openeo\n",
    "import pandas as pd\n",
    "import xarray\n",
    "from ipyleaflet import GeoJSON, Map, basemaps\n",
    "from openeo.processes import eq\n",
    "from openeo.rest.conversions import timeseries_json_to_pandas\n",
    "\n",
    "from fusets.analytics import phenology\n",
    "from fusets.mogpr import mogpr_1D\n",
    "from fusets.whittaker import whittaker\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "126b9754",
   "metadata": {},
   "source": [
    "# PART 1: Downloading the raw S2 NDVI time series\n",
    "\n",
    "We start by downloading the raw S2 NDVI data that we need for our analysis.\n",
    "\n",
    "Retrieving time series data can be done through various methods, and one such method is using openEO. [OpenEO](https://openeo.org/) is an API that provides access to a variety of Earth Observation (EO) data and processing services in a standardized and easy-to-use way. By leveraging the power of openEO, we can easily retrieve the time series data for the meadow and use it to analyze the patterns and trends.\n",
    "\n",
    "More information on the usage of openEO's Python client can be found on [GitHub](https://github.com/Open-EO/openeo-python-client).\n",
    "\n",
    "The first step is to connect to an openEO compatible backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f727d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d7ffd52",
   "metadata": {},
   "source": [
    "Check out also the free 30-day trial setup for openEO [here](https://docs.openeo.cloud/join/free_trial.html)!\n",
    "\n",
    "Next we define the area of interest, in this case an extent, for which we would like to fetch time series data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1970f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year = 2019\n",
    "spat_ext = {\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [-4.875091217039325, 41.77290587433312],\n",
    "            [-4.872773788450457, 41.77290587433312],\n",
    "            [-4.872773788450457, 41.77450614847532],\n",
    "            [-4.875091217039325, 41.77450614847532],\n",
    "            [-4.875091217039325, 41.77290587433312],\n",
    "        ]\n",
    "    ],\n",
    "    \"type\": \"Polygon\",\n",
    "}\n",
    "temp_ext = [f\"{year}-01-01\", f\"{year}-12-30\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ebb96d4",
   "metadata": {},
   "source": [
    "Plot the area to see what we're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = np.mean(spat_ext[\"coordinates\"][0], axis=0).tolist()[::-1]\n",
    "zoom = 16\n",
    "\n",
    "m = Map(basemap=basemaps.Esri.WorldImagery, center=center, zoom=zoom)\n",
    "g = GeoJSON(\n",
    "    data=spat_ext,\n",
    "    style={\n",
    "        \"color\": \"red\",\n",
    "        \"opacity\": 1,\n",
    "        \"weight\": 1.9,\n",
    "        \"dashArray\": \"9\",\n",
    "        \"fillOpacity\": 0.5,\n",
    "    },\n",
    ")\n",
    "m.add(g)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afa471c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will be working with with the rapeseed from 2019, located in the Nothern Spain.\n",
    "\n",
    "We will create an openEO process to calculate the NDVI time series for our area of interest. First we begin by using the `SENTINEL2_L2A_SENTINELHUB` collection, and apply a `Sen2Cor` cloud masking algorithm to remove any interfering clouds before calculating the NDVI values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94cc9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scl = connection.load_collection(\n",
    "    \"SENTINEL2_L2A_SENTINELHUB\",\n",
    "    spatial_extent=spat_ext,\n",
    "    temporal_extent=temp_ext,\n",
    "    bands=[\"SCL\"],\n",
    ")\n",
    "cloud_mask = scl.process(\n",
    "    \"to_scl_dilation_mask\",\n",
    "    data=scl,\n",
    "    kernel1_size=17, kernel2_size=77,\n",
    "    mask1_values=[2, 4, 5, 6, 7],\n",
    "    mask2_values=[3, 8, 9, 10, 11],\n",
    "    erosion_kernel_size=3)\n",
    "s2 = connection.load_collection(\n",
    "    \"SENTINEL2_L2A_SENTINELHUB\",\n",
    "    spatial_extent=spat_ext,\n",
    "    temporal_extent=temp_ext,\n",
    "    bands=[\"B04\", \"B08\", \"CLM\"],\n",
    ")\n",
    "s2 = s2.mask(cloud_mask)\n",
    "s2 = s2.mask_polygon(spat_ext)\n",
    "ndvi_cube = s2.ndvi(red=\"B04\", nir=\"B08\", target_band=\"NDVI\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee97be3e",
   "metadata": {},
   "source": [
    "If more information about a particular process is needed (such as the cloud masking), you can find out more the following way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf974e",
   "metadata": {},
   "outputs": [],
   "source": "connection.describe_process(\"to_scl_dilation_mask\")"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "968ec487",
   "metadata": {},
   "source": [
    "Now that we have calculated the NDVI time series for our area of interest, we can request openEO to download the result to our local storage. This will allow us to access the file and use it for further analysis in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecaffff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndvi_output_file = \"./raw_s2_ndvi_field.nc\"\n",
    "\n",
    "# the following code downloads the data, it is commented out,\n",
    "# since the data was prepared in advance to save time\n",
    "\n",
    "# ndvi_job = ndvi_cube.execute_batch(\n",
    "#     ndvi_output_file, title=f\"FOSS4G - FUSETS - Phenology - Raw NDVI\", out_format=\"netCDF\"\n",
    "# )\n",
    "\n",
    "# load the dataset and check it's structure\n",
    "raw_ndvi_ds = xarray.load_dataset(ndvi_output_file)\n",
    "raw_ndvi_ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c18c968",
   "metadata": {},
   "source": [
    "Plot the raw NDVI time series, averaged across the parcel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ndvi = raw_ndvi_ds.NDVI.rename({\"t\": \"time\"})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n",
    "\n",
    "raw_ndvi.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Raw NDVI\")\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89da90b7-f68c-4b63-8388-c92cd0f81835",
   "metadata": {},
   "source": [
    "## PART 2: Creating a smoothed dataset using Whittaker\n",
    "\n",
    "Whittaker smoother represents a computationally efficient reconstruction method for smoothing and gap-filling of time series which is why it is used here. (Eilers, P. H., 2003: A perfect smoother. Analytical chemistry, 75 (14), 3631â€“3636.)\n",
    "\n",
    "The Whittaker algorithm is available in the FuseTS toolbox as a **user-defined-function** (**UDF**) and can be used to create a smoothed time series. It employs a discrete penalized least squares algorithm that fits a smooth series, denoted as z, to the original data series, denoted as y.\n",
    "\n",
    "UDFs are convenient ways to apply your own custom algorithms on openEO datacubes. Read more about UDFs [here](https://openeo.org/documentation/1.0/udfs.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b96218-fa74-4d69-81b5-790daf95dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction every 5 days\n",
    "# to use the same dates as in the raw time series, just set the `prediction_period` to `None`\n",
    "smoothed = whittaker(raw_ndvi, prediction_period=\"P5D\", smoothing_lambda=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c1658a6",
   "metadata": {},
   "source": [
    "Plot the original raw NDVI as well as the smoothed NDVI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dde280-fc7c-4885-b789-ba2e6f746537",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n",
    "\n",
    "raw_ndvi.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Raw NDVI\", color=\"C0\")\n",
    "smoothed.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Smoothed NDVI\", color=\"C1\")\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0ecaa1e-ce08-4124-914f-65de784f03ff",
   "metadata": {},
   "source": [
    "## PART 3: Creating fused time series with MOGPR\n",
    "\n",
    "In this section, we will begin the process of creating our first fused dataset using the MOGPR (Multi-Output Gaussian Process Regression) technique. The process uses probabilistic theory to describe the time series using families of functions in a non-parametric way, and extracts the correlation between different inputs in order to merge the information together. The probabilistic nature of the process also provides uncertainty levels.\n",
    "\n",
    "The fusion process will involve combining Sentinel-1 (S1) RVI and Sentinel-2 (S2) NDVI data. To accomplish this, we will leverage the powerful capabilities of the FuseTS library.\n",
    "\n",
    "### Calculating the S1 RVI and S2 NVDI timeseries\n",
    "\n",
    "As the first step, we will use openEO to download the S1 RVI and S2 NDVI time series data required as input for the MOGPR service. This process ensures that we have the necessary data available for further fusion using the MOGPR algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a8742-bcea-4f9e-9465-98a98aa85274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for calculating RVI\n",
    "def calculate_rvi(dc):\n",
    "    VH = dc.band(\"VH\")\n",
    "    VV = dc.band(\"VV\")\n",
    "    return (VH + VH) / (VV + VH)\n",
    "\n",
    "\n",
    "# helper function for downloading S1 data\n",
    "def get_s1_data(ascending=True):\n",
    "    s1_data = connection.load_collection(\n",
    "        \"SENTINEL1_GRD\",\n",
    "        spatial_extent=spat_ext,\n",
    "        temporal_extent=temp_ext,\n",
    "        bands=[\"VH\", \"VV\"],\n",
    "        properties={\n",
    "            \"sat:orbit_state\": lambda x: eq(x, \"ASCENDING\" if ascending else \"DESCENDING\"),\n",
    "            \"resolution\": lambda x: eq(x, \"HIGH\"),\n",
    "            \"sar:instrument_mode\": lambda x: eq(x, \"IW\"),\n",
    "        },\n",
    "    )\n",
    "    return calculate_rvi(s1_data)\n",
    "\n",
    "\n",
    "# RVI ASCENDING\n",
    "rvi_asc_cube = get_s1_data(ascending=True)\n",
    "rvi_des_cube = get_s1_data(ascending=False)\n",
    "\n",
    "# NDVI\n",
    "ndvi_cube = s2.ndvi(red=\"B04\", nir=\"B08\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99a3d12a-6a42-41a3-8e25-45dcf9be0b80",
   "metadata": {},
   "source": [
    "Next, we will utilize openEO to calculate the time series for our Area of Interest (AOI) for each of the input datasets for MOGPR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5ef82-d05f-4902-9466-61dfb9dbad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"mogpr_input.csv\"\n",
    "\n",
    "# the following code downloads the data, it is commented out,\n",
    "# since the data was prepared in advance to save time\n",
    "\n",
    "# cubes_dfs = []\n",
    "# for cube in [ndvi_cube, rvi_asc_cube, rvi_des_cube]:\n",
    "#     timeseries = cube.polygonal_mean_timeseries(spat_ext).execute()\n",
    "#     timeseries_df = timeseries_json_to_pandas(timeseries)\n",
    "#     timeseries_df.index = pd.to_datetime(timeseries_df.index)\n",
    "#     cubes_dfs.append(timeseries_df)\n",
    "\n",
    "# # Join signals\n",
    "# mogpr_df = pd.concat(cubes_dfs, axis=1)\n",
    "# mogpr_df = mogpr_df.rename(columns={0: 'NDVI', 1: 'RVI_DESC', 2: 'RVI_ASC'})\n",
    "# mogpr_df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652deaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the downloaded tabular data, aggregated over parcel and over timestamp\n",
    "mogpr_df = pd.read_csv(output_file)\n",
    "mogpr_df[\"date\"] = pd.to_datetime(mogpr_df[\"date\"])\n",
    "mogpr_df.set_index(\"date\", inplace=True)\n",
    "mogpr_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5448001-03b8-444c-b4b7-8d7bfe703f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n",
    "\n",
    "style_dict = {\n",
    "    \"NDVI\": dict(marker=\"x\", color=\"C0\"),\n",
    "    \"RVI_DESC\": dict(marker=\"+\", color=\"C4\", lw=0),\n",
    "    \"RVI_ASC\": dict(marker=\".\", color=\"C4\", lw=0),\n",
    "}\n",
    "\n",
    "for col in mogpr_df.columns:\n",
    "    ax.plot(mogpr_df[col].dropna(), label=col, **style_dict[col])\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "ax.set_ylim([0, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0374a74-4d75-4dac-816d-50cfac52f3e1",
   "metadata": {},
   "source": [
    "### Executing MOGPR\n",
    "\n",
    "In order to process the time series data, some additional preprocessing is required to execute the MOGPR algorithm. This includes extracting the different time steps that are available in the input data.\n",
    "\n",
    "The step here may seem unnecessary, but it's merely transforming the data into a format which is expected by the `GPy` library containing the MOGPR logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512054b4-01f0-4598-84c0-934c7a7bddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only 2 signals\n",
    "signals = [\"RVI_DESC\", \"NDVI\"]\n",
    "\n",
    "doy_step = 5\n",
    "doy, data = [], []\n",
    "\n",
    "# create integer-nature time vectors for all inputs\n",
    "for signal in signals:\n",
    "    doy.append(mogpr_df.index.day_of_year.to_numpy())\n",
    "    data.append(mogpr_df[signal].to_numpy())\n",
    "\n",
    "doy_min = np.min(list(itertools.chain(*doy)))\n",
    "doy_max = np.max(list(itertools.chain(*doy)))\n",
    "output_doy = np.arange(doy_min, doy_max, doy_step)\n",
    "output_time = pd.to_datetime(output_doy, unit=\"D\", origin=datetime(2019, 1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7fb0221",
   "metadata": {},
   "source": [
    "The logic behing the MOGPR algorithm is quite complex and we will not go into details. A good place to start learning more is [this tutorial](https://nbviewer.org/github/SheffieldML/notebook/blob/master/GPy/coregionalized_regression_tutorial.ipynb).\n",
    "\n",
    "In principle, imagine the process doing the following:\n",
    "\n",
    "1. the model finds non-parametric descriptions of the time-series using a family of functions\n",
    "2. the model extracts the level of correlation between the inputs\n",
    "3. the model constructs the non-parametric outputwith optimal hyper-parameters for describing the functions and taking the correlations into account\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040dbf1-cc2d-467f-9a52-a7fd29795d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the MOGPR fit\n",
    "master_ind = 1\n",
    "out_mean, out_std, out_qflag, out_model = mogpr_1D(\n",
    "    data_in=data, time_in=doy, master_ind=master_ind, output_timevec=output_doy, nt=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c313461-1272-4b52-8a48-5a87ac2b2ec2",
   "metadata": {},
   "source": [
    "Let's convert the output of the service to a pandas dataframe and plot the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f04e8b-79cd-4544-9c5a-ebba41f3deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a pandas dataframe from the output\n",
    "mogpr = pd.DataFrame({\"NDVI\": out_mean[master_ind], \"NDVI_std\": out_std[master_ind]})\n",
    "mogpr[\"time\"] = output_time\n",
    "mogpr.set_index(\"time\", inplace=True)\n",
    "\n",
    "mogpr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc33055-5474-4d71-8c2d-b4eedd34cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n",
    "\n",
    "ax.plot(mogpr_df[\"NDVI\"].dropna(), \"x-\", color=\"C0\", label=\"Raw NDVI\")\n",
    "smoothed.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Smoothed NDVI\", color=\"C1\", alpha=0.3)\n",
    "\n",
    "ax.plot(mogpr[\"NDVI\"], \"x-\", color=\"C2\", label=\"Fused NDVI (MOGPR)\")\n",
    "ax.fill_between(\n",
    "    x=mogpr.index,\n",
    "    y1=mogpr[\"NDVI\"] - mogpr[\"NDVI_std\"],\n",
    "    y2=mogpr[\"NDVI\"] + mogpr[\"NDVI_std\"],\n",
    "    color=\"C2\",\n",
    "    alpha=0.25,\n",
    "    label=\"Fused NDVI (MOGPR) st.dev.\",\n",
    ")\n",
    "\n",
    "ax.set_ylim([0, 1])\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "702803f6",
   "metadata": {},
   "source": [
    "## PART 4: Creating the fused data set using CropSAR\n",
    "\n",
    "In the following section, we will leverage the capabilities of the toolbox to generate a fused dataset using CropSAR. The CropSAR service is specifically designed to enhance crop monitoring and analysis by integrating Sentinel-2 optical observations with Sentinel-1 radar data. This fusion process empowers users to monitor agricultural fields regardless of weather conditions or daylight availability, making it an invaluable tool for comprehensive crop assessment.\n",
    "\n",
    "To execute the CropSAR service and obtain the fused dataset, we will once again utilize openEO. By leveraging openEO, we can easily harness the power of CropSAR and efficiently download the fused dataset, enabling further analysis and extraction of valuable phenology information in the next part. The CropSAR service is exposed as a public openEO [user-defined process (UDP)](https://open-eo.github.io/openeo-python-client/udp.html#user-defined-processes), enabling easy re-use and integration into any existing workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f75a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = \"CropSAR_px\"\n",
    "namespace = \"vito\" # CropSAR at the moment only exists in the VITO namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropsar_cube = connection.datacube_from_process(\n",
    "    service,\n",
    "    namespace=namespace,\n",
    "    geometry=spat_ext,\n",
    "    startdate=temp_ext[0],\n",
    "    enddate=temp_ext[1],\n",
    "    version=2,\n",
    "    model_path=\"tmp/model/cnn_transformer/\",\n",
    "    path_extras=[\"tmp/env/env/\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a111459",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropsar_output_file = \"./cropsar_ndvi.nc\"\n",
    "\n",
    "# the following code downloads the data, it is commented out,\n",
    "# since the data was prepared in advance to save time\n",
    "\n",
    "# cropsar_job = cropsar_cube.execute_batch(\n",
    "#     cropsar_output_file,\n",
    "#     title=\"FOSS4G - FUSETS - Phenology - CropSAR\",\n",
    "#     out_format=\"netcdf\",\n",
    "#     job_options={\n",
    "#         \"executor-cores\": \"8\",\n",
    "#         \"task-cpus\": \"8\",\n",
    "#         \"executor-memoryOverhead\": \"2g\",\n",
    "#         \"udf-dependency-archives\": [\n",
    "#             \"https://artifactory.vgt.vito.be/auxdata-public/cropsar_px/20230504T175919_cnn_transformer.zip#tmp/model/cnn_transformer\",\n",
    "#             \"https://artifactory.vgt.vito.be/auxdata-public/cropsar_px/env.tar.gz#tmp/env\",\n",
    "#         ],\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# load the dataset and check it's structure\n",
    "cropsar_ds = xarray.load_dataset(cropsar_output_file)\n",
    "cropsar_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropsar = cropsar_ds.NDVI.rename({\"t\": \"time\"}) / 255  # from uint8 to float32\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n",
    "\n",
    "raw_ndvi.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Raw NDVI\", color=\"C0\")\n",
    "smoothed.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"Smoothed NDVI\", color=\"C1\", alpha=0.3)\n",
    "mogpr[\"NDVI\"].plot(ax=ax, marker=\"x\", label=\"Fused NDVI (MOGPR)\", color=\"C2\", alpha=0.3)\n",
    "cropsar.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", label=\"CropSAR fused NDVI\", color=\"C3\")\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0719218",
   "metadata": {},
   "source": [
    "## PART 5: Phenology calculation\n",
    "\n",
    "In this final step, we will utilize both the raw and CropSAR-based time series data to extract valuable phenology information. To accomplish this, we will employ the `phenology` service. By leveraging this service, we can extract a range of essential metrics, including the start, peak, and end of the growing season.\n",
    "\n",
    "The calculation is based on the [phenolopy]() python package.\n",
    "\n",
    "![phenolopy](https://github.com/lewistrotter/Phenolopy/raw/main/documentation/images/pheno_explain.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d345da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run phenology on raw NDVI\n",
    "raw_phenology = phenology(raw_ndvi)\n",
    "\n",
    "# run phenology on Whittaker smoothed\n",
    "whittaker_phenology = phenology(smoothed)\n",
    "\n",
    "# run phenology on MOGPR\n",
    "mogpr_phenology = phenology(mogpr.to_xarray().NDVI)\n",
    "\n",
    "# run phenology on fused NDVI\n",
    "cropsar_phenology = phenology(cropsar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d89f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to extract phenology metrics\n",
    "def get_phenology_metric(phenology_data, metric):\n",
    "    if \"x\" in phenology_data.dims:\n",
    "        metric_data = phenology_data[metric].median([\"x\", \"y\"]).values.take(0)\n",
    "    else:\n",
    "        metric_data = phenology_data[metric].values.take(0)\n",
    "\n",
    "    return datetime(year, 1, 1) + timedelta(days=metric_data if not np.isnan(metric_data) else 0)\n",
    "\n",
    "\n",
    "for title, metric in zip([\"Start of season\", \"Peak of season\", \"End of season\"], [\"sos\", \"pos\", \"eos\"]):\n",
    "    fig, ax = plt.subplots(figsize=(15, 5), dpi=120)\n",
    "\n",
    "    raw_ndvi.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", color=\"C0\", label=\"Raw Data\")\n",
    "    smoothed.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", color=\"C1\", label=\"Smoothed Data (Whittaker)\")\n",
    "    mogpr[\"NDVI\"].plot(ax=ax, marker=\"x\", color=\"C2\", label=\"Fused Data (MOGPR)\")\n",
    "    cropsar.median(dim=[\"x\", \"y\"]).plot(ax=ax, marker=\"x\", color=\"C3\", label=\"Fused Data (CropSAR)\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "\n",
    "    ax.axvline(get_phenology_metric(raw_phenology, f\"{metric}_times\"), color=\"C0\")\n",
    "    ax.axvline(get_phenology_metric(whittaker_phenology, f\"{metric}_times\"), color=\"C1\")\n",
    "    ax.axvline(get_phenology_metric(mogpr_phenology, f\"{metric}_times\"), color=\"C2\")\n",
    "    ax.axvline(get_phenology_metric(cropsar_phenology, f\"{metric}_times\"), color=\"C3\")\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "272377b5-05b7-4145-9938-8d3ec1fd7d2e",
   "metadata": {},
   "source": [
    "The basic phenology metrics (Start Of Season(SOS), Peak Of Season(POS), End Of Season(EOS)) are presented above.\n",
    "In this case, SOS and EOS are calculated using one of the available methodologies, first of slope. This allows to characterize the seasonality of the crop.\n",
    "\n",
    "With this last step, an integral workflow is demonstrated: from the raw data acquisition and fused time series generation to the retrieval of phenology metrics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c03b434e59eed88f0de80727dd778a0649e6474303457c247ef449eabdd7cac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
